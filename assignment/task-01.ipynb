{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 01: Introduction to Pytorch\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The goal of this task is to get us thinking not just about training models, but about our *training pipelines*.\n",
    "\n",
    "A neural network is a function, $f$, that accepts in data inputs, $\\boldsymbol{X}$, and weights, $\\boldsymbol{\\Theta}$ that produces labels $\\boldsymbol{\\hat{y}}$,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\hat{y}} = f(\\Theta; \\boldsymbol{X}).\n",
    "$$\n",
    "\n",
    "Meanwhile, a neural network training process, is itself a function, $g$, which accepts as input a dataset $x$, and for supervised algorithms a set of targets $y$, along with a set of parameters $\\boldsymbol{\\Omega}$ which define how the process is performed, and produces as output the weights of a neural network, $\\boldsymbol{\\Theta}$,\n",
    "\n",
    "$$\n",
    "\\Theta = g(\\boldsymbol{\\Omega}; \\boldsymbol{X}, \\boldsymbol{y}).\n",
    "$$\n",
    "\n",
    "It is helpful to think of the training function, $g$, as a pipeline, composed of several training steps, which can include preprocessing, post processing, etc.\n",
    "\n",
    "$$\n",
    "g = g_N \\circ\\ \\cdots\\ \\circ g_1.\n",
    "$$\n",
    "\n",
    "For example, $g_1$ might be a preprocessing step, then $g_2$ might be a training step, and $g_3$ might be a pruning step in a basic pipeline where data $(\\boldsymbol{X}, \\boldsymbol{y})$ goes in and weights $\\boldsymbol{\\Theta}$ come out.\n",
    "\n",
    "We will learn to think of the training process this way by modifying some example code for a basic MNIST classification task. We begin with some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "'widget is not a recognised GUI loop or backend name",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/matplotlib/backends/registry.py:413\u001b[0m, in \u001b[0;36mBackendRegistry.resolve_gui_or_backend\u001b[0;34m(self, gui_or_backend)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgui_or_backend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# KeyError ?\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/matplotlib/backends/registry.py:375\u001b[0m, in \u001b[0;36mBackendRegistry.resolve_backend\u001b[0;34m(self, backend)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gui \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a recognised backend name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend, gui \u001b[38;5;28;01mif\u001b[39;00m gui \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheadless\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 'widget' is not a recognised backend name",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwidget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/IPython/core/magics/pylab.py:103\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;241m%\u001b[39m _list_matplotlib_backends_and_gui_loops()\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_matplotlib_backend(args\u001b[38;5;241m.\u001b[39mgui, backend)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3665\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3662\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib_inline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_inline\u001b[39;00m\n\u001b[1;32m   3664\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pylabtools \u001b[38;5;28;01mas\u001b[39;00m pt\n\u001b[0;32m-> 3665\u001b[0m gui, backend \u001b[38;5;241m=\u001b[39m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_gui_and_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpylab_gui_select\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gui \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3668\u001b[0m     \u001b[38;5;66;03m# If we have our first gui selection, store it\u001b[39;00m\n\u001b[1;32m   3669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/IPython/core/pylabtools.py:349\u001b[0m, in \u001b[0;36mfind_gui_and_backend\u001b[0;34m(gui, gui_select)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     gui \u001b[38;5;241m=\u001b[39m _convert_gui_to_matplotlib(gui)\n\u001b[0;32m--> 349\u001b[0m     backend, gui \u001b[38;5;241m=\u001b[39m \u001b[43mbackend_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve_gui_or_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m gui \u001b[38;5;241m=\u001b[39m _convert_gui_from_matplotlib(gui)\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gui, backend\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/matplotlib/backends/registry.py:415\u001b[0m, in \u001b[0;36mBackendRegistry.resolve_gui_or_backend\u001b[0;34m(self, gui_or_backend)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_backend(gui_or_backend)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# KeyError ?\u001b[39;00m\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgui_or_backend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a recognised GUI loop or backend name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 'widget is not a recognised GUI loop or backend name"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "%matplotlib widget\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from dataclasses import dataclass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 01 - Part 1\n",
    "\n",
    "Your first task is to:\n",
    "\n",
    "* Add layer definitions to the following neural network class\n",
    "* Define the forward pass\n",
    "\n",
    "You can find starting architectures online. It is important to know there is no known theory to identify a best architecture *before* starting the problem. Trial and error (by iterative training and testing) is the only way to prove or disprove the utility of an architecture.\n",
    "\n",
    "That said, recall some intuition about the way linear and nonlinear transforms work. We know we need a chain of both to have any hope of solving this problem. We also know that we need some depth, and cannot solve this problem by width alone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        raise NotImplementedError(\"Not implemented!\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError(\"Not implemented!\")\n",
    "        # Uncomment the return once implemented\n",
    "        # return output\n",
    "\n",
    "\n",
    "def run_training_epoch(\n",
    "    training_params, model, device, train_loader, optimizer, epoch\n",
    "):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % training_params.log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(data),\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "            if training_params.dry_run:\n",
    "                break\n",
    "\n",
    "\n",
    "def predict(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(\n",
    "                output, target, reduction=\"sum\"\n",
    "            ).item()  # sum up batch loss\n",
    "            pred = output.argmax(\n",
    "                dim=1, keepdim=True\n",
    "            )  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss,\n",
    "            correct,\n",
    "            len(test_loader.dataset),\n",
    "            100.0 * correct / len(test_loader.dataset),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Code: Training Pipeline\n",
    "\n",
    "For this assignment, the training pipeline is defined for you. Notice the similarities to the mathematical description of a trainer we saw above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingParameters:\n",
    "    \"\"\"Training parameters for a simple neural network trainer.\"\"\"\n",
    "\n",
    "    batch_size: int = 64\n",
    "    test_batch_size: int = 1000\n",
    "    epochs: int = 14\n",
    "    lr: float = 1.0\n",
    "    gamma: float = 0.7\n",
    "    normalizer_mean = 0.1307\n",
    "    normalizer_std = 0.3081\n",
    "    no_cuda: bool = True  # Enable or disable CUDA\n",
    "    no_mps: bool = True  # Enable or disable GPU on MacOS\n",
    "    dry_run: bool = False\n",
    "    seed: int = 1\n",
    "    log_interval: int = 10\n",
    "    save_model: bool = True\n",
    "\n",
    "\n",
    "def configure_training_device(training_params):\n",
    "    use_cuda = not training_params.no_cuda and torch.cuda.is_available()\n",
    "    use_mps = not training_params.no_mps and torch.backends.mps.is_available()\n",
    "\n",
    "    torch.manual_seed(training_params.seed)\n",
    "\n",
    "    if use_cuda:\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif use_mps:\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    train_kwargs = {\"batch_size\": training_params.batch_size}\n",
    "    test_kwargs = {\"batch_size\": training_params.test_batch_size}\n",
    "\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {\"num_workers\": 1, \"pin_memory\": True, \"shuffle\": True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "    return device, train_kwargs, test_kwargs\n",
    "\n",
    "\n",
    "def build_preprocessing_transform(training_params):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                (training_params.normalizer_mean,),\n",
    "                (training_params.normalizer_std,),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return transform\n",
    "\n",
    "\n",
    "def build_data_loaders(train_kwargs, test_kwargs, transform):\n",
    "    dataset1 = datasets.MNIST(\n",
    "        \"../data\", train=True, download=True, transform=transform\n",
    "    )\n",
    "    dataset2 = datasets.MNIST(\"../data\", train=False, transform=transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def train(training_params, device, train_loader, test_loader):\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=training_params.lr)\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=training_params.gamma)\n",
    "\n",
    "    for epoch in range(1, training_params.epochs + 1):\n",
    "        run_training_epoch(\n",
    "            training_params, model, device, train_loader, optimizer, epoch\n",
    "        )\n",
    "        predict(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        if training_params.save_model:\n",
    "            torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Execute a Training Pipeline\n",
    "\n",
    "With our training steps defined in modular fashion, we can easily define and execute a training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_training_pipeline():\n",
    "    training_params = TrainingParameters(epochs=1, dry_run=True)\n",
    "    device, train_kwargs, test_kwargs = configure_training_device(\n",
    "        training_params\n",
    "    )\n",
    "    transform = build_preprocessing_transform(training_params)\n",
    "    train_loader, test_loader = build_data_loaders(\n",
    "        train_kwargs, test_kwargs, transform\n",
    "    )\n",
    "    train(training_params, device, train_loader, test_loader)\n",
    "\n",
    "\n",
    "execute_training_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 01 - Part 2: Explore Width\n",
    "\n",
    "Using the example above, define a network with a single hidden layer.\n",
    "\n",
    "Modify the trainer to store the train and test errors in a numpy vector.\n",
    "\n",
    "Create a for loop over to iterate through a few different amounts of hidden neurons and train until convergence (when the error stops decreasing) each time.\n",
    "\n",
    "Save the minimum error achieved and plot it with respect to the number of hidden nodes.\n",
    "\n",
    "(It should be hard to get good convergence here - this is part of the exercise.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 01 - Part 3: Explore Depth\n",
    "\n",
    "Now using the example above, define several networks with increasing numbers of hidden layers (either convolutional or fully connected).\n",
    "\n",
    "As above, create a for loop over to iterate through a few different depths and train until convergence (when the error stops decreasing) each time.\n",
    "\n",
    "Save the minimum error achieved and plot it with respect to the number of hidden nodes.\n",
    "\n",
    "This example should converge much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
